Open source day was a bit of a blowout for me. I spent the day exactly as I shouldnt, browsing around looking at code and issues and not doing nearly enough engaging. I still want to look out for things to have a hand in in the future.

Thunder talk work: Data-Scraping. browser automation 

pre-intro, why did I choose this topic: learning about api's i took on board the idea that the more data you have , the cooler things you can create. Also all though my experience with web dev the structure of our apps is always responding to user events so the idea of automation is wicked cool.

intro - write last, to introduce the stuff you come up with

format of scraping is sending request to a website, Im using superagent to do that. Use a second tool to access the elements of the webpage, this is where the real scraping happens. 



Puppeteer - my scraping
Generate screenshots and PDFs of pages.
Crawl a SPA and generate pre-rendered content (i.e. "SSR").
Scrape content from websites.
Automate form submission, UI testing, keyboard input, etc.
Create an up-to-date, automated testing environment. Run your tests directly in the latest version of Chrome using the latest JavaScript and browser features.
Capture a timeline trace of your site to help diagnose performance issues.
https://github.com/GoogleChrome/puppeteer



Cheerio - harrison scraping


osmosis super nice tool wowee, no large dependencies which is a bonus over cheerio and puppeteer.

scrapy python

I'd like to touch on a few scraping methods for the sake of filling things out and have examples of how they work.

I'd also like to talk about scraping. why its used, its origins and other weird stuff about it.

automation - testing - information gathering idk :)

Conclusion: scraping has a vigilante feel. Independent hackerman

[hackerman](http://i0.kym-cdn.com/entries/icons/original/000/021/807/4d7.png)
